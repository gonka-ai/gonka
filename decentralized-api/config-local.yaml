nodes:
  - id: node1
    url:  http://34.171.235.205:8080/ # Deployed inference node
    max_concurrent: 500
    models:
      - unsloth/llama-3-8b-Instruct
chain_node:
  url: http://localhost:26657/
  account_name: "alice"
  keyring_backend: "test"
  keyring_dir: "~/.inference" # We use a custom function to expand ~ to /root
