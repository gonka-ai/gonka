api:
  port: 8080
nodes:
  - id: node1
    host:  34.171.235.205 # Deployed inference node
    inference_port: 8080
    poc_port: 5000
    max_concurrent: 500
    models:
      - unsloth/llama-3-8b-Instruct
chain_node:
  url: http://node:26657
  account_name: "executor"
  keyring_backend: "test"
  keyring_dir: "/root/.inference"
