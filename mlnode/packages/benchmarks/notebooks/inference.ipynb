{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_FULL = \"http://58.186.149.100:19001/\"\n",
    "URL_QUANTIZED = \"http://58.186.149.100:19002/\"\n",
    "MAX_TOKENS = 3000\n",
    "TEMPERATURE = 0.99\n",
    "SEED = 42\n",
    "LOGPROBS = 4\n",
    "\n",
    "\n",
    "from validation.prompts import get_squad_data_questions\n",
    "from validation.runner import run_validation\n",
    "from validation.data import (\n",
    "    ModelInfo,\n",
    "    RequestParams,\n",
    "    save_to_jsonl\n",
    ")\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"unsloth/llama-3-8b-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def get_squad_data_questions() -> List[str]:\n",
    "    dataset = load_dataset('squad', keep_in_memory=True)\n",
    "    prompts = []\n",
    "    \n",
    "    train_prompts = [f\"Context: {context}\\nQuestion: {question} \" for question, context in zip(dataset['train']['question'], dataset['train']['context'])]\n",
    "    prompts.extend(train_prompts)\n",
    "    \n",
    "    validation_prompts = [f\"Context: {context}\\nQuestion: {question} \" for question, context in zip(dataset['validation']['question'], dataset['validation']['context'])]\n",
    "    prompts.extend(validation_prompts)\n",
    "    \n",
    "    return prompts\n",
    "\n",
    "prompts = get_squad_data_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_info = ModelInfo(\n",
    "    url=\"http://58.186.149.100:19002/\",\n",
    "    name=\"Qwen/Qwen2.5-7B-Instruct\",\n",
    "    deploy_params={\n",
    "        \"GPU\": \"1xA100\",\n",
    "        \"precision\": \"fp8\",\n",
    "    }\n",
    ")\n",
    "\n",
    "quantized_model_info = ModelInfo(\n",
    "    url=\"http://58.186.149.100:19001/\",\n",
    "    name=\"Qwen/Qwen2.5-7B-Instruct-AWQ\",\n",
    "    deploy_params={\n",
    "        \"GPU\": \"1xA100\",\n",
    "        \"precision\": \"int4\",\n",
    "    }\n",
    ")\n",
    "\n",
    "request_params = RequestParams(\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    temperature=TEMPERATURE,\n",
    "    seed=SEED,\n",
    "    top_logprobs=LOGPROBS\n",
    ")\n",
    "\n",
    "inference_model_info = full_model_info\n",
    "validation_model_info = full_model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'squad-all_qwen25-7B_fp8_val-fp8.jsonl'\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "prompts = prompts\n",
    "\n",
    "for start_idx in range(0, len(prompts), batch_size):\n",
    "    prompt_batch = prompts[start_idx:start_idx + batch_size]\n",
    "    results_batch = run_validation(\n",
    "        prompt_batch,\n",
    "        inference_model=inference_model_info,\n",
    "        validation_model=validation_model_info,\n",
    "        request_params=request_params,\n",
    "        max_workers=50\n",
    "    )\n",
    "    save_to_jsonl(results_batch, DATA_PATH, append=True)\n",
    "    print(f\"Processed {start_idx + batch_size} from {len(prompts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
